{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Nemo Microservices Deployment and Customization, evaluation, inference flow\n",
    "\n",
    "The following diagram illustrates how the NeMo microservices construct a data flywheel in a scenario for model customization and evaluation.\n",
    "\n",
    "<center><img src=\"./images-dli/nemo-platform-customization-workflow.png\" style=\"width: 800px;\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Local Lab's Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0.1 Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Kubernetes Controlplane IP\n",
    "minikube_ip=!minikube ip\n",
    "minikube_ip=minikube_ip[0]\n",
    "minikube_ip\n",
    "\n",
    "# Define endpoints\n",
    "data_store_url = \"http://nemo-datastore.local\"\n",
    "nim_url = \"http://llama3-1-8b-instruct.local\"\n",
    "eval_url = \"http://nemo-evaluator.local\"\n",
    "entity_store_url = \"http://nemo-entity-store.local\"\n",
    "customizer_url = \"http://nemo-customizer.local\"\n",
    "nim_internal_endpoint=\"http://meta-llama3-1-8b-instruct.llama3-1-8b-instruct.svc.cluster.local:8000\"\n",
    "\n",
    "health_check_endpoints = {\n",
    "    \"DataStore\": f\"{data_store_url}/v1/health\",\n",
    "    \"EntityStore\": f\"{entity_store_url}/v1/health/ready\",\n",
    "    \"NIM\": f\"{nim_url}/v1/health/ready\",\n",
    "    \"Evaluator\": f\"{eval_url}/health\",\n",
    "    \"Customizer\": f\"{customizer_url}/health/ready\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0.2 Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import urllib3\n",
    "from pprint import pprint\n",
    "import json\n",
    "import requests\n",
    "from huggingface_hub import configure_http_backend\n",
    "from huggingface_hub import HfApi\n",
    "from IPython.display import JSON\n",
    "import time\n",
    "# Disable SSL warnings\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def wait_for_rollouts(deployments, check_interval=5):\n",
    "    \"\"\"\n",
    "    Waits for all specified Kubernetes deployments to be successfully rolled out.\n",
    "\n",
    "    Parameters:\n",
    "    - deployments (list of tuples): List of (namespace, deployment_name) pairs.\n",
    "    - check_interval (int): Time in seconds to wait between rollout status checks.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        all_ready = True  # Flag to track if all deployments are ready\n",
    "\n",
    "        for namespace, deployment in deployments:\n",
    "            # Run kubectl rollout status command for the current deployment\n",
    "            result = subprocess.run(\n",
    "                [\"kubectl\", \"rollout\", \"status\", f\"deployment/{deployment}\", \"-n\", namespace, \"--timeout=5s\"],\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True\n",
    "            )\n",
    "\n",
    "            # Check if the deployment is fully rolled out\n",
    "            if \"successfully rolled out\" not in result.stdout:\n",
    "                all_ready = False  # Mark that at least one deployment is not ready\n",
    "                print(f\"Waiting for {deployment} in {namespace} namespace to be ready...\")\n",
    "\n",
    "        if all_ready:\n",
    "            print(\"All deployments are ready!\")\n",
    "            break  # Exit the loop when all deployments are ready\n",
    "\n",
    "        time.sleep(check_interval)  # Wait before checking again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0.3 Check the status of Nemo MS deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployments = [\n",
    "    (\"nemo-customizer\", \"nemo-customizer-api\"),\n",
    "    (\"nemo-datastore\", \"nemo-datastore\"),\n",
    "    (\"nemo-entity-store\", \"nemo-entity-store\"),\n",
    "    (\"nemo-evaluator\", \"nemo-evaluator\"),\n",
    "    (\"llama3-1-8b-instruct\", \"meta-llama3-1-8b-instruct\")\n",
    "]\n",
    "# Call the function to wait for all deployments to be ready\n",
    "wait_for_rollouts(deployments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0.4 Check health status of Nemo Microservices (Get pods)\n",
    "\n",
    "Example output \n",
    "\n",
    "```\n",
    "nemo-customizer            nemo-customizer-api-5d9c8f9cb5-4wmvp                              1/1     Running     0               33m\n",
    "nemo-customizer            nemo-customizer-opentelemetry-collector-5c477756f4-792jc          1/1     Running     0               5h43m\n",
    "nemo-datastore             nemo-datastore-5d45d56869-v7ttg                                   1/1     Running     0               98m\n",
    "nemo-entity-store          nemo-entity-store-79b56cc6c5-hvmts                                1/1     Running     0               34m\n",
    "nemo-evaluator             nemo-evaluator-5564df495f-dtn5x                                   1/1     Running     0               5h44m\n",
    "nemo-kubernetes-operator   nemo-kubernetes-operator-customizer-controller-manager-8fc8nrqf   2/2     Running     0               35m\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods -A | grep nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0.5 Check health status of each Nemo Microservices\n",
    "\n",
    "We have defined above the endpoints, and here we try to check the health endpoint of each and see all are healthy or not\n",
    "\n",
    "Example output\n",
    "\n",
    "```json\n",
    "{'Customizer': {'response': '{\"status\":\"healthy\"}', 'status_code': 200},\n",
    " 'DataStore': {'response': '{\\n'\n",
    "                           '  \"status\": \"pass\",\\n'\n",
    "                           '  \"description\": \"Datastore\",\\n'\n",
    "                           '  \"checks\": {\\n'\n",
    "                           '    \"cache:ping\": [\\n'\n",
    "                           '      {\\n'\n",
    "                           '        \"status\": \"pass\",\\n'\n",
    "                           '        \"time\": \"2025-02-18T11:46:18Z\"\\n'\n",
    "                           '      }\\n'\n",
    "                           '    ],\\n'\n",
    "                           '    \"database:ping\": [\\n'\n",
    "                           '      {\\n'\n",
    "                           '        \"status\": \"pass\",\\n'\n",
    "                           '        \"time\": \"2025-02-18T11:46:18Z\"\\n'\n",
    "                           '      }\\n'\n",
    "                           '    ]\\n'\n",
    "                           '  }\\n'\n",
    "                           '}',\n",
    "               'status_code': 200},\n",
    " 'EntityStore': {'response': '{\"status\":\"ready\"}', 'status_code': 200},\n",
    " 'Evaluator': {'response': '{\"status\":\"healthy\"}', 'status_code': 200},\n",
    " 'NIM': {'response': '{\"object\":\"health.response\",\"message\":\"Service is '\n",
    "                     'ready.\"}',\n",
    "         'status_code': 200}}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check health status\n",
    "health_status = {}\n",
    "for name, url in health_check_endpoints.items():\n",
    "    try:\n",
    "        response = requests.get(url, verify=False, timeout=5)\n",
    "        health_status[name] = {\"status_code\": response.status_code, \"response\": response.text}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        health_status[name] = {\"error\": str(e)}\n",
    "\n",
    "# Print results\n",
    "pprint(health_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Fine-Tuning\n",
    "\n",
    "This section is focused on fine-tuning a model (`llama-3.1-8-b-instruct`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 Create Global Variables\n",
    "\n",
    "These variables define key names used in the fine-tuning process:\n",
    "- ```namespace```: Defines a logical grouping (like a workspace) in which datasets and models are managed.\n",
    "- ```dataset_name```: Specifies the name of the dataset being created.\n",
    "- ```project_name```: Represents the project associated with this fine-tuning task.\n",
    "- ```new_model_name```: Defines the name of the new fine-tuned model.\n",
    "\n",
    "\n",
    "```HF_ENDPOINT```: This constructs the API endpoint for Hugging Face-compatible interactions using data_store_url, likely pointing to an internal model/dataset store like NVIDIA Nemo Datastore.\n",
    "\n",
    "```HF_TOKEN```: A placeholder for an authentication token, required to interact with the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = \"default\"\n",
    "dataset_name=\"test-dataset\"\n",
    "project_name=\"example-project\"\n",
    "new_model_name=\"example-model@v2\"\n",
    "\n",
    "#Define the endpoint and token\n",
    "HF_ENDPOINT = f\"{data_store_url}/v1/hf\"\n",
    "HF_TOKEN = \"token\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1.1 Configure HF Backend \n",
    "\n",
    "`backend_factory` function creates an HTTP session using the requests library.\n",
    "`session.verify` = False disables SSL verification.\n",
    "\n",
    "\n",
    "`hf_api` is an instance of HfApi, which is an API client for interacting with the Hugging Face-compatible backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backend_factory() -> requests.Session:\n",
    "    session = requests.Session()\n",
    "    session.verify = False\n",
    "    return session\n",
    "\n",
    "configure_http_backend(backend_factory=backend_factory)\n",
    "\n",
    "hf_api = HfApi(endpoint=HF_ENDPOINT, token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.2 Create a Dataset in Nemo DataStore\n",
    "\n",
    "This step involves invoking the Nemo Datastore API to create a dataset repository.\n",
    "Expected Behavior:\n",
    "\n",
    "- A request is sent to the Nemo Datastore API.\n",
    "- The dataset `example-dataset` is created in the default namespace.\n",
    "- The dataset gets a `repository_id`, which uniquely identifies it.\n",
    "\n",
    "Example output\n",
    "\n",
    "```\n",
    "RepoUrl('datasets/default/test-dataset', endpoint='http://nemo-datastore.local/v1/hf', repo_type='dataset', repo_id='default/test-dataset')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = f\"{namespace}/{dataset_name}\"\n",
    "repo_type = \"dataset\"\n",
    "\n",
    "hf_api.create_repo(repo_id, repo_type=repo_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2.1 Verify Datasets in DataStore\n",
    "\n",
    "Expected output: \n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"id\": \"default/test-dataset\",\n",
    "    \"name\": \"test-dataset\",\n",
    "    \"created_at\": \"2025-02-22T23:31:52.000000001Z\",\n",
    "    \"last_modified\": \"2025-02-22T23:31:52.000000001Z\"\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl $data_store_url/v1/hf/api/datasets | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.3 Upload the training, testting and validation files into the Dataset\n",
    "\n",
    "This step involves uploading training, testing, and validation files into the Nemo Datastore. The dataset repository has already been created in the previous step (`5.1.2`), and now we are adding the actual data.\n",
    "\n",
    "- The training, testing, and validation datasets (typically in .jsonl format) are stored in a local directory. We already have created a sample datasets for you in the following folders: \n",
    "    - Training: `./dataset/training/`\n",
    "    - Testing:  `./dataset/testing/`\n",
    "    - Validation: `./dataset/validation/`\n",
    "- The notebook uploads these files to the Nemo Datastore, making them available for fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3.1 Check the training dataset\n",
    "\n",
    "```\n",
    "{\n",
    "  \"prompt\": \"Who designed the Gold State Coach? Adjacent to the palace is the Royal Mews, also designed by Nash, where the royal carriages, including the Gold State Coach, are housed. This rococo gilt coach, designed by Sir William Chambers in 1760, has painted panels by G. B. Cipriani. It was first used for the State Opening of Parliament by George III in 1762 and has been used by the monarch for every coronation since George IV. It was last used for the Golden Jubilee of Elizabeth II. Also housed in the mews are the coach horses used at royal ceremonial processions. Answer: \",\n",
    "  \"completion\": \"Sir William Chambers\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head -n 2 /dli/task/dataset/training/training.jsonl | jq '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3.2 Upload all the files to training, testing and validation folders\n",
    "\n",
    "This step uploads the dataset (training, testing, and validation) to the Nemo Datastore repository using the `hf_api.upload_folder()` method.\n",
    "\n",
    "\n",
    "- `folder_path`: Specifies the local path of the training dataset.\n",
    "- `repo_id`: Refers to the repository identifier where the dataset is stored on Nemo Datastore.\n",
    "- `repo_type` Defines the type of repository (`dataset` in this case).\n",
    "- `path_in_repo`: Creates a folder named example `training` inside the repository where the uploaded files will be stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output : \n",
    "\n",
    "```\n",
    "CommitInfo(commit_url='', commit_message='Upload folder using huggingface_hub', commit_description='', oid='4c6b40743a16139133b897bbbd6b172228ccc854', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_folder = \"/dli/task/dataset/training\"  # Path to the folder\n",
    "testing_data_folder = \"/dli/task/dataset/testing\"  # Path to the folder\n",
    "validation_data_folder = \"/dli/task/dataset/validation\"  # Path to the folder\n",
    "\n",
    "# Upload the folder\n",
    "hf_api.upload_folder(\n",
    "    folder_path=training_data_folder,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=repo_type,\n",
    "    path_in_repo=\"training\"\n",
    ")\n",
    "\n",
    "hf_api.upload_folder(\n",
    "    folder_path=testing_data_folder,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=repo_type,\n",
    "    path_in_repo=\"testing\"\n",
    ")\n",
    "\n",
    "CommitInfo = hf_api.upload_folder(\n",
    "    folder_path=validation_data_folder,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=repo_type,\n",
    "    path_in_repo=\"validation\"\n",
    ")\n",
    "CommitInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3.3 Check uploaded files\n",
    "\n",
    "Example Output:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"sha\": \"25c5ceb2d33e05176b146b0d162cb61c1852fae5\",\n",
    "    \"size\": 130,\n",
    "    \"path\": \"testing/testing.jsonl\"\n",
    "  },\n",
    "  {\n",
    "    \"sha\": \"25d7e14bb8fafb4a1390a8b4c499093f58480589\",\n",
    "    \"size\": 131,\n",
    "    \"path\": \"training/training.jsonl\"\n",
    "  },\n",
    "  {\n",
    "    \"sha\": \"64ace1aabee4eb2f9ddf15ddfdebbc8e28a15189\",\n",
    "    \"size\": 130,\n",
    "    \"path\": \"validation/validation.jsonl\"\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl  \"$data_store_url/v1/hf/api/datasets/$namespace/$dataset_name/tree/$CommitInfo.oid\" | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.4 Register Dataset in Nemo Entity Store \n",
    "\n",
    "After uploading the dataset to the Nemo Datastore , the next step is registering it in the Nemo Entity Store. This ensures that the dataset is officially recognized and can be accessed by other components of the system.\n",
    "\n",
    "\n",
    "Example output:\n",
    "\n",
    "```json\n",
    "{\n",
    " 'schema_version': '1.0',\n",
    " 'id': 'dataset-7Sztzr5MuXVNwifSCBNrZk',\n",
    " 'description': 'This is an example of dataset',\n",
    " 'type_prefix': None,\n",
    " 'namespace': 'default',\n",
    " 'project': 'example-project',\n",
    " 'created_at': '2025-02-18T13:53:47.921652',\n",
    " 'updated_at': '2025-02-18T13:53:47.921654',\n",
    " 'custom_fields': {},\n",
    " 'ownership': None,\n",
    " 'name': 'example-dataset',\n",
    " 'version_id': 'main',\n",
    " 'version_tags': [],\n",
    " 'format': None,\n",
    " 'files_url': 'hf://datasets/default/example-dataset'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4.1 Register Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{entity_store_url}/v1/datasets\"\n",
    "\n",
    "headers = { 'accept': 'application/json'}\n",
    "\n",
    "data = {\n",
    "      \"name\": dataset_name,\n",
    "      \"namespace\": namespace,\n",
    "      \"description\": \"This is an example of dataset\",\n",
    "      \"files_url\": f\"hf://datasets/{namespace}/{dataset_name}\",\n",
    "      \"project\": project_name\n",
    "}\n",
    "\n",
    "response=requests.request(\"POST\", url, headers=headers, json=data, verify=False)\n",
    "response_entity = response.json()\n",
    "response_entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4.2 Check Datasets in Nemo Entity Store\n",
    "\n",
    "Example Output\n",
    "```json\n",
    "{\n",
    "  \"object\": \"list\",\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"created_at\": \"2025-02-22T23:57:31.696208\",\n",
    "      \"updated_at\": \"2025-02-22T23:57:31.696209\",\n",
    "      \"name\": \"test-dataset\",\n",
    "      \"namespace\": \"default\",\n",
    "      \"description\": \"This is an example of dataset\",\n",
    "      \"files_url\": \"hf://datasets/default/test-dataset\",\n",
    "      \"project\": \"example-project\",\n",
    "      \"custom_fields\": {}\n",
    "    }\n",
    "  ],\n",
    "  \"pagination\": {\n",
    "    \"page\": 1,\n",
    "    \"page_size\": 10,\n",
    "    \"current_page_size\": 1,\n",
    "    \"total_pages\": 1,\n",
    "    \"total_results\": 1\n",
    "  },\n",
    "  \"sort\": \"created_at\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl $entity_store_url/v1/datasets | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.5 Creating a Customization Job for llama-3.1-8b-instruct Using Nemo Customizer\n",
    "\n",
    "This step submits a customization job to fine-tune the ```meta/llama-3.1-8b-instruct``` model using Nemo Customizer. The process involves configuring the model, specifying the dataset, setting hyperparameters, and defining training parameters.\n",
    "\n",
    "1. Prepare the Data for Fine-Tuning\n",
    "    - `config`: Specifies the base model to fine-tune (meta/llama-3.1-8b-instruct).\n",
    "    - `dataset`: Defines which dataset to use for training.\n",
    "        - `name`: The name of the dataset (e.g., \"example-dataset\").\n",
    "        - `namespace`: The namespace where the dataset is stored (e.g., \"default\").\n",
    "\n",
    "2. Define Fine-Tuning Hyperparameters\n",
    "\n",
    "```python\n",
    "\"hyperparameters\": {\n",
    "           \"training_type\": \"sft\",\n",
    "           \"finetuning_type\": \"lora\",\n",
    "           \"epochs\": 10,\n",
    "           \"batch_size\": 16,\n",
    "           \"learning_rate\": 0.0001,\n",
    "           \"lora\": {\"adapter_dim\": 16}\n",
    "        },\n",
    "```\n",
    "3. Define Model Details\n",
    "    - `enabled`: \"true\" → Enables fine-tuning.\n",
    "    - `finetuning_types`: Specifies \"lora\" as the fine-tuning method.\n",
    "    - `max_seq_length`: Maximum sequence length (4096 tokens).\n",
    "    - `micro_batch_size`: 1 → Number of samples per GPU before accumulating gradients.\n",
    "    - `model_path`: Path to the base model (/mount/models/llama-3_1-8b-instruct).\n",
    "    - `num_gpus`: Uses 1 GPU.\n",
    "    - `num_nodes`: Uses 1 node.\n",
    "    - `num_parameters`: Model size (8 billion parameters).\n",
    "    - `precision`: \"bf16\" (Brain Floating Point 16-bit precision).\n",
    "    - `tensor_parallel_size`: 1 (Single GPU per tensor parallelism).\n",
    "    \n",
    "4. Define output model name\n",
    "```json\n",
    "\"output_model\": new_model_name\n",
    "```\n",
    "\n",
    "<center><img src=\"./images-dli/nemo_customizer.png\" style=\"width: 800px;\"></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{customizer_url}/v1/customization/jobs\"\n",
    "headers = { 'accept': 'application/json'}\n",
    "\n",
    "data = {\n",
    "    \"config\": \"meta/llama-3.1-8b-instruct\",\n",
    "        \"dataset\": {\n",
    "           \"name\": dataset_name,\n",
    "           \"namespace\": namespace\n",
    "        },\n",
    "        \"hyperparameters\": {\n",
    "           \"training_type\": \"sft\",\n",
    "           \"finetuning_type\": \"lora\",\n",
    "           \"epochs\": 1,\n",
    "           \"batch_size\": 32,\n",
    "           \"learning_rate\": 0.001,\n",
    "           \"lora\": {\"adapter_dim\": 16}\n",
    "        },\n",
    "        \"project\": project_name,\n",
    "        \"model\": {\n",
    "            \"enabled\": \"true\", \n",
    "            \"finetuning_types\": [\"lora\"], \n",
    "            \"max_seq_length\": 4096, \n",
    "            \"micro_batch_size\": 1, \n",
    "            \"model_path\": \"/mount/models/llama-3_1-8b-instruct\", \n",
    "            \"name\": \"meta/llama-3.1-8b-instruct\", \n",
    "            \"num_gpus\": 1, \n",
    "            \"num_nodes\": 1, \n",
    "            \"num_parameters\": 8000000000, \n",
    "            \"precision\": \"bf16\", \n",
    "            \"tensor_parallel_size\": 1\n",
    "        },\n",
    "        \"ownership\": {\n",
    "           \"created_by\": \"me\",\n",
    "           \"access_policies\": {\n",
    "              \"arbitrary\": \"json\"\n",
    "           }\n",
    "        },\n",
    "        \"output_model\": new_model_name\n",
    "}\n",
    "\n",
    "response=requests.request(\"POST\", url, headers=headers, json=data, verify=False)\n",
    "response_customization = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check customization response\n",
    "response_customization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.6  Check Customization Job Status\n",
    "\n",
    "In this section, we will be querying the status of the customization job submitted earlier.\n",
    "\n",
    "1. Get the Customization Job ID\n",
    "    - After submitting the customization job, the response contains the job details, including the job ID.\n",
    "    - `response_customization[\"id\"]` extracts the job ID from the response.\n",
    "2. The status endpoint URL is constructed using the `customizer_url` and the customization job ID.\n",
    "       `http://nemo-customizer.local/v1/customization/jobs/{response_customization_id}/status`\n",
    "3. After submitting the request, response will contain details about the current status of the customization job.\n",
    "    - It might return status information like \"queued\", \"in-progress\", or \"completed\".\n",
    "    - It  also provide timestamps, error messages, or additional status information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.6.1 Check Customization status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response_customization_id = response_customization[\"id\"]\n",
    "url = f\"{customizer_url}/v1/customization/jobs/{response_customization_id}/status\"\n",
    "\n",
    "headers = { 'accept': 'application/json'}\n",
    "\n",
    "response=requests.request(\"GET\", url, headers=headers, verify=False)\n",
    "response= response.json()\n",
    "JSON(response, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.6.2 Check Customization pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods -n nemo-customizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.6.3 Check logs of job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customizer_worker_pod_name= ! kubectl get pods -n nemo-customizer | grep training-job-worker-0 | cut -d' ' -f1\n",
    "!kubectl logs  {customizer_worker_pod_name[0]}  -n nemo-customizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.6.4 Continuously Check Customization Job Status until its completed\n",
    "\n",
    "\n",
    "Example output depending on how many steps you ran this for. You can see the training and validation loss.  \n",
    "\n",
    "```\n",
    "Status: completed, Progress: 100.0%\n",
    "Final Response:\n",
    "{'created_at': '2025-02-23T00:07:43.991608',\n",
    " 'updated_at': '2025-02-23T01:05:01.498712',\n",
    " 'status': 'completed',\n",
    " 'steps_completed': 230,\n",
    " 'epochs_completed': 10,\n",
    " 'percentage_done': 100.0,\n",
    " 'best_epoch': 4,\n",
    " 'train_loss': 0.18880946934223175,\n",
    " 'val_loss': 0.39688706398010254,\n",
    " 'metrics': {'keys': ['train_loss', 'val_loss'],\n",
    "  'metrics': {'train_loss': [{'value': 3.227027177810669,\n",
    "     'step': 9,\n",
    "     'timestamp': '2025-02-23T00:12:21.263000'},\n",
    "    {'value': 2.7157721519470215,\n",
    "     'step': 19,\n",
    "     'timestamp': '2025-02-23T00:14:32.493000'},\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_customization_id = response_customization[\"id\"]\n",
    "url = f\"{customizer_url}/v1/customization/jobs/{response_customization_id}/status\"\n",
    "\n",
    "headers = {'accept': 'application/json'}\n",
    "\n",
    "while True:\n",
    "    response = requests.request(\"GET\", url, headers=headers, verify=False).json()\n",
    "    \n",
    "    status = response.get(\"status\")\n",
    "    percentage_done = response.get(\"percentage_done\", 0.0)\n",
    "    \n",
    "    print(f\"Status: {status}, Progress: {percentage_done}%\")\n",
    "\n",
    "    if status in [\"completed\", \"failed\"]:\n",
    "        break\n",
    "\n",
    "    time.sleep(120)  # Wait for 5 seconds before checking again\n",
    "\n",
    "print(\"Final Response:\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "It takes 10 minutes to complete.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.6.5 Check Customization metrics in mlflow\n",
    "In this section, you will monitoring the metrics of the customization job in MLflow, a popular machine learning lifecycle management platform. The key steps are outlined below and shown in diagram below:\n",
    "\n",
    "1. Before you can access the customization metrics, the MLflow endpoint needs to be exposed and accessible.\n",
    "2. Now that the endpoint is available, you can query metrics related to your custom model (in your case, \"example-model@v2\"). \n",
    "\n",
    "<img src=\"./images-dli/mlflow-model.png\" style=\"width: 435px; float: left\">\n",
    "<img src=\"./images-dli/mlflow-cust.png\" style=\"width: 500px; float: right\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.Popen(\n",
    "    [\"kubectl\", \"-n\", \"mlflow\", \"port-forward\", \"--address\", \"0.0.0.0\", \"service/mlflow-tracking\", \"30090:80\"],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    "    close_fds=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%js\n",
    "const href = window.location.hostname;\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open MLFlow UI!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href + \"/mlflow/\";\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.7 Check Nemo Entity Store Models API to list New Lora Adapter Model \n",
    "\n",
    "This step involves querying Nemo Entity Store's API to verify that the newly created LoRA adapter model has been successfully registered and is available in the store. The NeMo Entity Store acts as a metadata store where models, datasets, and other ML-related artifacts are tracked.\n",
    "\n",
    "You will see the name as :'example-model@v2',\n",
    "Example output:\n",
    "\n",
    "```json\n",
    "{'object': 'list',\n",
    " 'data': [{'created_at': '2025-02-23T00:07:44.036516',\n",
    "   'updated_at': '2025-02-23T00:07:44.036518',\n",
    "   'name': 'example-model@v2',\n",
    "   'namespace': 'default',\n",
    "   'description': 'None',\n",
    "   'spec': {'num_parameters': 8000000000,\n",
    "    'context_size': 4096,\n",
    "    'num_virtual_tokens': 0,\n",
    "    'is_chat': False},\n",
    "   'artifact': {'gpu_arch': 'Ampere',\n",
    "    'precision': 'bf16',\n",
    "    'tensor_parallelism': 1,\n",
    "    'backend_engine': 'nemo',\n",
    "    'status': 'created',\n",
    "    'files_url': 'hf://default/example-model@v2'},\n",
    "   'base_model': 'meta/llama-3.1-8b-instruct',\n",
    "   'peft': {'finetuning_type': 'lora'},\n",
    "   'schema_version': '1.0',\n",
    "   'project': 'customizer',\n",
    "   'custom_fields': {}}],\n",
    " 'pagination': {'page': 1,\n",
    "  'page_size': 10,\n",
    "  'current_page_size': 1,\n",
    "  'total_pages': 1,\n",
    "  'total_results': 1},\n",
    " 'sort': 'created_at'}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nemo Entity Store endpoint\n",
    "\n",
    "url = f\"{entity_store_url}/v1/models\"\n",
    "\n",
    "headers = { 'accept': 'application/json'}\n",
    "\n",
    "response=requests.request(\"GET\", url, headers=headers, verify=False)\n",
    "response_entity = response.json()\n",
    "JSON(response_entity, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.8 Check NIM Models API to list New Lora Adapter Model \n",
    "This step involves using the NIM  Models API to check whether the newly fine-tuned LoRA adapter model is registered and available for deployment.\n",
    "\n",
    "You will see new lora adapter (`example-model@v2`) as part of the NIM API: \n",
    "\n",
    "```\n",
    "{'object': 'list',\n",
    " 'data': [{'id': 'meta/llama-3.1-8b-instruct',\n",
    "   'object': 'model',\n",
    "   'created': 1740273131,\n",
    "   'owned_by': 'system',\n",
    "   'root': 'meta/llama-3.1-8b-instruct',\n",
    "   'parent': None,\n",
    "   'max_model_len': 131072,\n",
    "   'permission': [{'id': 'modelperm-37abc8fbdf7c4f93a28965c8b687820d',\n",
    "     'object': 'model_permission',\n",
    "     'created': 1740273131,\n",
    "     'allow_create_engine': False,\n",
    "     'allow_sampling': True,\n",
    "     'allow_logprobs': True,\n",
    "     'allow_search_indices': False,\n",
    "     'allow_view': True,\n",
    "     'allow_fine_tuning': False,\n",
    "     'organization': '*',\n",
    "     'group': None,\n",
    "     'is_blocking': False}]},\n",
    "  {'id': 'example-model@v2',\n",
    "   'object': 'model',\n",
    "   'created': 1740273131,\n",
    "   'owned_by': 'system',\n",
    "   'root': 'hf://default/example-model@v2',\n",
    "   'parent': 'meta/llama-3.1-8b-instruct',\n",
    "   'max_model_len': None,\n",
    "   'permission': [{'id': 'modelperm-e01b3c55f1664c0bb73862c743ce5257',\n",
    "     'object': 'model_permission',\n",
    "     'created': 1740273131,\n",
    "     'allow_create_engine': False,\n",
    "     'allow_sampling': True,\n",
    "     'allow_logprobs': True,\n",
    "     'allow_search_indices': False,\n",
    "     'allow_view': True,\n",
    "     'allow_fine_tuning': False,\n",
    "     'organization': '*',\n",
    "     'group': None,\n",
    "     'is_blocking': False}]}]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NIM endpoint\n",
    "url = f\"{nim_url}/v1/models\"\n",
    "\n",
    "headers = { 'accept': 'application/json'}\n",
    "\n",
    "response=requests.request(\"GET\", url, headers=headers, verify=False)\n",
    "response_nim = response.json()\n",
    "JSON(response_nim, expanded=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.9  Evaluation using NeMo Evaluator\n",
    "This step describes the NeMo Evaluator workflow, which is used to assess the performance of models (such as fine-tuned LLMs) by running inference, computing metrics, and storing evaluation results.\n",
    "A typical NeMo Evaluator workflow looks like the following:\n",
    "\n",
    "1. (Optional) If you are using a custom dataset for evaluation, upload it to NeMo Data Store before you run an evaluation.\n",
    "2. Create an evaluation target in NeMo Evaluator.\n",
    "    - The evaluation target specifies which model is being evaluated.\n",
    "    - This is typically the fine-tuned LoRA adapter model or another LLM in NeMo Entity Store.\n",
    "\n",
    "3. Create an evaluation configuration in NeMo Evaluator. This step defines the evaluation parameters, including:\n",
    "    - Dataset to use for evaluation\n",
    "    - Evaluation metrics (e.g., BLEU, Rouge, perplexity)\n",
    "    - Evaluation mode (e.g., zero-shot, fine-tuned performance)\n",
    "\n",
    "4. Run an evaluation job by submitting a request to NeMo Evaluator.\n",
    "    - NeMo Evaluator downloads custom data, if any, from NeMo Data Store.\n",
    "    - NeMo Evaluator runs inference with NIM for LLMs, Embeddings, and Reranking, depending on the model being evaluated.\n",
    "    - NeMo Evaluator writes the results, including generations, logs, and metrics to NeMo Data Store.\n",
    "    - NeMo Evaluator returns the results.\n",
    "5. Get the results.\n",
    "\n",
    "<center><img src=\"./images-dli/nemo_eval.png\" style=\"width: 800px;\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.9.1 Create Evaluation Target\n",
    "\n",
    "    - The evaluation target specifies which model is being evaluated.\n",
    "    - This is typically the fine-tuned LoRA adapter model or another LLM in NeMo Entity Store.\n",
    "\n",
    "Example output: \n",
    "```\n",
    "{'namespace': '-',\n",
    " 'name': 'eval-target-Py6Yb7aY46T22PktdDRY1V',\n",
    " 'type': 'model',\n",
    " 'model': {'api_endpoint': {'url': 'http://meta-llama3-1-8b-instruct.llama3-1-8b-instruct.svc.cluster.local:8000/v1/completions',\n",
    "   'model_id': 'example-model@v2',\n",
    "   'api_key': None},\n",
    "  'cached_outputs': None},\n",
    " 'retriever': None,\n",
    " 'rag': None,\n",
    " 'tags': None,\n",
    " 'id': 'eval-target-Py6Yb7aY46T22PktdDRY1V'}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{eval_url}/v1/evaluation/targets\"\n",
    "print(url)\n",
    "headers = { 'accept': 'application/json'}\n",
    "\n",
    "data = {\n",
    "      \"type\": \"model\",\n",
    "       \"model\": {\n",
    "            \"api_endpoint\": {\n",
    "                \"url\": f\"{nim_internal_endpoint}/v1/completions\",\n",
    "                \"model_id\": new_model_name\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "response=requests.request(\"POST\", url, headers=headers, json=data, verify=False)\n",
    "response_eval_target = response.json()\n",
    "JSON(response_eval_target, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.9.2 Create Evaluation Config\n",
    "\n",
    "This step defines the evaluation parameters, including:\n",
    "- Dataset to use for evaluation\n",
    "- Evaluation metrics (e.g., BLEU, Rouge, perplexity)\n",
    "- Evaluation mode (e.g., zero-shot, fine-tuned performance)\n",
    "\n",
    "example output: \n",
    "\n",
    "```\n",
    "{'id': 'eval-config-4mg8tWWJuQMHrC9ozHi7Sg',\n",
    " 'namespace': '-',\n",
    " 'name': 'eval-config-4mg8tWWJuQMHrC9ozHi7Sg',\n",
    " 'type': 'similarity_metrics',\n",
    " 'tags': [],\n",
    " 'tasks': [{'type': 'default',\n",
    "   'params': {'tokens_to_generate': 200,\n",
    "    'temperature': 0.7,\n",
    "    'top_k': 20,\n",
    "    'n_samples': -1},\n",
    "   'dataset': {'files_url': 'nds:default/test-dataset/testing/testing.jsonl'},\n",
    "   'metrics': [{'name': 'accuracy'},\n",
    "    {'name': 'bleu'},\n",
    "    {'name': 'rouge'},\n",
    "    {'name': 'em'},\n",
    "    {'name': 'f1'}]}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{eval_url}/v1/evaluation/configs\"\n",
    "headers = { 'accept': 'application/json'}\n",
    "\n",
    "data = {\n",
    "      \"type\": \"similarity_metrics\",\n",
    "      \"tasks\": [\n",
    "         {\n",
    "            \"type\": \"default\",\n",
    "            \"dataset\": {\n",
    "               \"files_url\": f\"nds:{namespace}/{dataset_name}/testing/testing.jsonl\"\n",
    "            },\n",
    "            \"metrics\": [\n",
    "               {\n",
    "                  \"name\": \"accuracy\"\n",
    "               },\n",
    "               {\n",
    "                  \"name\": \"bleu\"\n",
    "               },\n",
    "               {\n",
    "                  \"name\": \"rouge\"\n",
    "               },\n",
    "               {\n",
    "                  \"name\": \"em\"\n",
    "               },\n",
    "               {\n",
    "                  \"name\": \"f1\"\n",
    "               }\n",
    "            ],\n",
    "            \"params\": {\n",
    "               \"tokens_to_generate\": 200,\n",
    "               \"temperature\": 0.7,\n",
    "               \"top_k\": 20,\n",
    "               \"n_samples\": -1\n",
    "            }\n",
    "         }\n",
    "      ]\n",
    "}\n",
    "\n",
    "response=requests.request(\"POST\", url, headers=headers, json=data, verify=False)\n",
    "response_eval_config = response.json()\n",
    "JSON(response_eval_config, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.9.3 Create Evaluation\n",
    "\n",
    "Now combing the above created target and configuration we perform evaluation. This evaluation creates a sequence of jobs. \n",
    "\n",
    "Example output: \n",
    "\n",
    "```\n",
    "{'namespace': '-',\n",
    " 'name': 'eval-YRmL6ZEGELomrZXCdJ3W7K',\n",
    " 'tags': None,\n",
    " 'id': 'eval-YRmL6ZEGELomrZXCdJ3W7K',\n",
    " 'target': {'namespace': '-',\n",
    "  'name': 'eval-target-EmThWsr9vTeEdJmYyVduAq',\n",
    "  'type': 'model',\n",
    "  'model': {'api_endpoint': {'url': 'http://meta-llama3-1-8b-instruct.llama3-1-8b-instruct.svc.cluster.local:8000/v1/completions',\n",
    "    'model_id': 'example-model@v2',\n",
    "    'api_key': None},\n",
    "   'cached_outputs': None},\n",
    "  'retriever': None,\n",
    "  'rag': None,\n",
    "  'tags': None,\n",
    "  'id': 'eval-target-EmThWsr9vTeEdJmYyVduAq'},\n",
    " 'config': {'id': 'eval-config-4mg8tWWJuQMHrC9ozHi7Sg',\n",
    "  'namespace': '-',\n",
    "  'name': 'eval-config-4mg8tWWJuQMHrC9ozHi7Sg',\n",
    "  'type': 'similarity_metrics',\n",
    "  'tags': [],\n",
    "  'params': None,\n",
    "  'tasks': [{'type': 'default',\n",
    "    'params': {'tokens_to_generate': 200,\n",
    "     'temperature': 0.7,\n",
    "     'top_k': 20,\n",
    "     'n_samples': -1},\n",
    "    'dataset': {'files_url': 'nds:default/test-dataset/testing/testing.jsonl',\n",
    "     'format': None},\n",
    "    'metrics': [{'name': 'accuracy', 'params': None},\n",
    "     {'name': 'bleu', 'params': None},\n",
    "     {'name': 'rouge', 'params': None},\n",
    "     {'name': 'em', 'params': None},\n",
    "     {'name': 'f1', 'params': None}]}],\n",
    "  'aggregate_metrics': None},\n",
    " 'status': 'initializing',\n",
    " 'created_at': '2025-02-23T01:17:25Z'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{eval_url}/v1/evaluation/jobs\"\n",
    "headers = { 'accept': 'application/json'}\n",
    "\n",
    "data = {\n",
    "      \"target_id\": response_eval_target[\"id\"],\n",
    "      \"config_id\": response_eval_config[\"id\"]\n",
    "}\n",
    "\n",
    "response=requests.request(\"POST\", url, headers=headers, json=data, verify=False)\n",
    "response_eval = response.json()\n",
    "JSON(response_eval, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.10 Check Evaluation Status\n",
    "After submitting an evaluation job in NeMo Evaluator, we can track its status.\n",
    "This step checks that the evaluation is running successfully and retrieves the final results.\n",
    "\n",
    "1. Once the evaluation request is submitted, we extract the evaluation job ID from the response.\n",
    "2. We send a GET request to NeMo Evaluator's API to retrieve the job status.\n",
    "\n",
    "You will observe the status something like below: \n",
    "```\n",
    "'status': {'name': 'evaluation',\n",
    "  'level': 'evaluation',\n",
    "  'status': 'running',\n",
    "  'message': None,\n",
    "  'jobs': [],\n",
    "  'children': []},\n",
    " 'created_at': '2025-02-23T01:17:25Z',\n",
    " 'results': []}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation_id = response_eval[\"id\"]\n",
    "\n",
    "url = f\"{eval_url}/v1/evaluation/jobs/-/{evaluation_id}\"\n",
    "headers = { 'accept': 'application/json'}\n",
    "\n",
    "response=requests.request(\"GET\", url, headers=headers, verify=False)\n",
    "\n",
    "response_eval_status = response.json()\n",
    "response_eval_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.10.1 Check Evaluation Status in ArgoWorkflow\n",
    "\n",
    "Since NeMo Evaluator uses Argo Workflows (a Kubernetes-native workflow orchestrator), we can also check the evaluation status directly in Argo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.Popen(\n",
    "    [\"kubectl\", \"-n\", \"argoworkflows\", \"port-forward\", \"--address\", \"0.0.0.0\", \"service/argo-workflows-server\", \"31091:2746\"],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    "    close_fds=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%js\n",
    "const href = window.location.hostname;\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Argoworkflow UI!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href + \"/\";\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Argo Workflows UI\n",
    "\n",
    "Once you open the Argo Workflows UI: \n",
    "1. Click on the workflows option from the side menu.\n",
    "2. Remove the namespace selection and you will see the workflow run by Nemo Evaluator.\n",
    "    \n",
    "<img src=\"./images-dli/argoworkflows-ui.png\" style=\"width: 250px; float: left\">\n",
    "<img src=\"./images-dli/argoworkflows-ui-2.png\" style=\"width: 700px; float: right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluator Workflow in Argoworkflows\n",
    "1. Click on the `eval-commands-..` workflow\n",
    "2. It will open up the sequential/DAG graph workflow run by Nemo Evaluator.\n",
    "3. You can click on each component to see details and logs about those steps.\n",
    "\n",
    "<img src=\"./images-dli/eval-workflow.png\" style=\"width: 430px; float: left\">\n",
    "<img src=\"./images-dli/eval-workflow-logs.png\" style=\"width: 500px; float: right\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.11 Perform Inference\n",
    "After training and evaluating the new LoRA-adapted model, the next step is to perform inference using it.\n",
    "This involves sending a request to the NIM API. We will here compare the response with both the lora-adapted model and the original model. \n",
    "\n",
    "Note: We haven't fully finetuned the model as we only ran for 2 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.11.1 Using the New Model\n",
    "\n",
    "You will see the response as 1714, which is what we have in the testing dataset. \n",
    "\n",
    "```\n",
    "{'id': 'cmpl-b9d840aa5340443287d708dacea0151b',\n",
    " 'object': 'text_completion',\n",
    " 'created': 1740273275,\n",
    " 'model': 'example-model@v2',\n",
    " 'choices': [{'index': 0,\n",
    "   'text': '1714',\n",
    "   'logprobs': None,\n",
    "   'finish_reason': 'stop',\n",
    "   'stop_reason': 128001,\n",
    "   'prompt_logprobs': None}],\n",
    " 'usage': {'prompt_tokens': 57, 'total_tokens': 60, 'completion_tokens': 3}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"When was the war of Spanish Succession? The decline of Catalan continued in the 16th and 17th centuries. The Catalan defeat in the War of Spanish Succession (1714) initiated a series of measures imposing the use of Spanish in legal documentation. Answer: \"\n",
    "data = {\n",
    "  \"model\": new_model_name,\n",
    "  \"prompt\": prompt,\n",
    "  \"temperature\": 1.0,\n",
    "  \"nvext\": {\"top_k\": 1,\n",
    "          \"top_p\": 0.0\n",
    "           },\n",
    "  \"max_tokens\": 100,\n",
    "}\n",
    "\n",
    "headers = {'accept': 'application/json', 'Content-Type': 'application/json'}\n",
    "\n",
    "\n",
    "llm_response = requests.post(f\"{nim_url}/v1/completions\", headers=headers, json=data,verify=False)\n",
    "# See LLM response\n",
    "JSON(llm_response.json(), expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.11.2 Using the base Foundational Model\n",
    "\n",
    "Here also the answer is 1714, but the output tokens are quite high with all other information included. \n",
    "\n",
    "```\n",
    "{'id': 'cmpl-11b728544c0b4860a00086efe2775990',\n",
    " 'object': 'text_completion',\n",
    " 'created': 1740273343,\n",
    " 'model': 'meta/llama-3.1-8b-instruct',\n",
    " 'choices': [{'index': 0,\n",
    "   'text': '1714. The War of the Spanish Succession (1701-1714) was a global conflict that involved many European powers. The War of the Spanish Succession (1701-1714) was a global conflict that involved many European powers. The War of the Spanish Succession (1701-1714) was a global conflict that involved many European powers. The War of the Spanish Succession (1701-1714) was a global conflict that involved many European powers. The',\n",
    "   'logprobs': None,\n",
    "   'finish_reason': 'length',\n",
    "   'stop_reason': None,\n",
    "   'prompt_logprobs': None}],\n",
    " 'usage': {'prompt_tokens': 57, 'total_tokens': 157, 'completion_tokens': 100}}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"When was the war of Spanish Succession? The decline of Catalan continued in the 16th and 17th centuries. The Catalan defeat in the War of Spanish Succession (1714) initiated a series of measures imposing the use of Spanish in legal documentation. Answer: \"\n",
    "data = {\n",
    "  \"model\": \"meta/llama-3.1-8b-instruct\",\n",
    "  \"prompt\": prompt,\n",
    "  \"temperature\": 1.0,\n",
    "  \"nvext\": {\"top_k\": 1,\n",
    "          \"top_p\": 0.0\n",
    "           },\n",
    "  \"max_tokens\": 100,\n",
    "}\n",
    "\n",
    "headers = {'accept': 'application/json', 'Content-Type': 'application/json'}\n",
    "\n",
    "llm_response = requests.post(f\"{nim_url}/v1/completions\", headers=headers, json=data,verify=False)\n",
    "# See LLM response\n",
    "JSON(llm_response.json(), expanded=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "You've made it through the fifth Notebook. In this notebook, you have:\n",
    "- Checked health status of all the Nemo Microservices endpoints.\n",
    "- Run through the E2E fine-tuning pipeline using all the Nemo Microservices\n",
    "    - Create a dataset store in Nemo-Datastore.\n",
    "    - Added training, test and validation files in the dataset.\n",
    "    - Created a customization job via Nemo-Customizer on a foundational model.\n",
    "    - Observed the customization job metrics in the MLFlow.\n",
    "    - Created Evaluation job of the fine-tuned/customized model via Nemo-Evaluator.\n",
    "    - Execute the inference both on the fine-tuned and base foundational model. \n",
    "\n",
    "Next, you'll see learn to run automation E2E fine-tuning pipeline using  ArgoWorkflowsin [06_Fine_Tuning_Automation_Pipelines.ipynb](06_Fine_Tuning_Automation_Pipelines.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
